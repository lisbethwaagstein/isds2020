{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** In most sessions you will be solving exercises posed in a Jupyter notebook that looks like this one. Because you are cloning a Github repository that only we can push to, you should **NEVER EDIT** any of the files you pull from Github. Instead, what you should do, is either make a new notebook and write your solutions in there, or **make a copy of this notebook and save it somewhere else** on your computer, not inside the `sds` folder that you cloned, so you can write your answers in there. If you edit the notebook you pulled from Github, those edits (possible your solutions to the exercises) may be overwritten and lost the next time you pull from Github. This is important, so don't hesitate to ask if it is unclear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Exercise Set 8: Advanced Scrapers\n",
    "\n",
    "In this Exercise Set we shall develop our webscraping skills even further by practicing using `Selenium` while   parsing and navigating html trees using `BeautifoulSoup`. Furthermore we will train extracting information from raw text with no html tags to help, using regular expressions. \n",
    "\n",
    "But just as importantly you will get a chance to think about **data quality issues** and how to ensure reliability when curating your own webdata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 8.1: Translating domains into companies\n",
    "This exercise is about solving a problem that danish companies are facing. They all want to use external data such as customer review data to gain more knowledge about their customers and maybe even use the information as features in their models. There is just one problem: users rate domains not companies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.1:** You work for the danish authorities and are currently staffed to a project where you have to reduce the amount of dangerous toys. You have build a webscraper that collect user reviews form Trustpilot and have identified some websites that got a bad reputation among its users. You belive that the risk of them selling illegal or dangerous toys might be bigger than some of the bg brands with good ratings and decide to investigate them. \n",
    "\n",
    "> Go to the website https://www.dk-hostmaster.dk/da/find-domaenenavn with selenium and search for \"netbaby.dk\". Store the name of the registrant \"Euphemia Media\" in the variable `company`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer 8.1.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Cache is valid for [12/08/2020]\n",
      "[WDM] - Looking for [chromedriver 84.0.4147.30 mac64] driver in cache \n",
      "[WDM] - Driver found in cache [/Users/nicklasjohansen/.wdm/drivers/chromedriver/84.0.4147.30/mac64/chromedriver]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "url = 'https://www.dk-hostmaster.dk/da/find-domaenenavn'\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.implicitly_wait(5000)\n",
    "driver.get(url)\n",
    "\n",
    "question = driver.find_element_by_id('popup-buttons')\n",
    "question.click()\n",
    "\n",
    "inputElement = driver.find_element_by_id('query_domain')\n",
    "inputElement.click()\n",
    "inputElement.send_keys('netbaby.dk')\n",
    "inputElement.send_keys(Keys.RETURN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company: euphemia media\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "company = soup.select(\"#domain_registrant_name\")\n",
    "company = str(company)\n",
    "company = re.findall('(?<=>)(.*)(?=<)', company)[0]\n",
    "company = company.lower()\n",
    "print('company:', company)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.2:** Now you know who owns the domain and would like to know more about the company `euphemia media`. \n",
    "\n",
    "> Go to the Central Business Register website https://datacvr.virk.dk/data/. Figure out how to look up companies by changing the url and then lookup `euphemia media`. Store the CVR number in the variable `cvr` and print it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer 8.1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.3:** Congratulations. You are now able to translate domains into companies and by that enrich what ever analysis you want to make. Let's say that you were to build a scraper who could translate thousands of domains. What kind of errors can you imagine running into and how would you mitigate them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer 8.1.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I would look into**\n",
    "\n",
    "1. Some doomains are owned by privates and is not present in CVR.  \n",
    "\n",
    "2. Company names for organizations might have one name in DK Hostmaster and another on CVR (fx. PRICEWATERHOUSECOOPERS STATSAUTORISERET)  \n",
    "\n",
    "3. Is there any limitations using these website in our virual browser? Maybe our cnnection will be shut down if we make 1000 request in one hours or put too much pressure on their servers? If you want to work with CVR I recommed that you sign up for their [API](https://datacvr.virk.dk/data/cvr-hj%C3%A6lp/cvr-adgange). It is free and well documented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 8.2: Practicing Regular Expressions.\n",
    "This exercise is about developing your experience with designing your own regular expressions.\n",
    "\n",
    "Remember you can always consult the regular expression reference page [here](https://www.regular-expressions.info/refquick.html), if you need to remember or understand a specific symbol. \n",
    "\n",
    "You should practice using *\"define-inspect-refine-method\"* described in the lectures to systematically ***explore*** and ***refine*** your expressions, and save all the patterns tried. You can download the small module that I created to handle this in the following way: \n",
    "``` python\n",
    "import requests\n",
    "url = 'https://raw.githubusercontent.com/snorreralund/explore_regex/master/explore_regex.py'\n",
    "response = requests.get(url)\n",
    "with open('explore_regex.py','w') as f:\n",
    "    f.write(response.text)\n",
    "import explore_regex as e_re\n",
    "```\n",
    "\n",
    "Remember to start ***broad*** to gain many examples, and iteratively narrow and refine.\n",
    "\n",
    "We will use a sample of the trustpilot dataset that you practiced collecting yesterday.\n",
    "You can load it directly into python from the following link: https://raw.githubusercontent.com/snorreralund/scraping_seminar/master/english_review_sample.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.1:** Load the data used in the exercise using the `pd.read_csv` function. (Hint: path to file can be both a url or systempath). \n",
    "\n",
    ">Define a variable `sample_string = '\\n'.join(df.sample(2000).reviewBody)` as sample of all the reviews that you will practice on.  (Run it once in a while to get a new sample for potential differences).\n",
    "Imagine we were a company wanting to find the reviews where customers are concerned with the price of a service. They decide to write a regular expression to match all reviews where a currencies and an amount is mentioned. \n",
    "\n",
    "> **Ex. 8.2.2:** \n",
    "> Write an expression that matches both the dollar-sign (\\$) and dollar written literally, and the amount before or after a dollar-sign. Remember that the \"$\"-sign is a special character in regular expressions. Explore and refine using the explore_pattern function in the package I created called explore_regex. \n",
    "```python\n",
    "import explore_regex as e_re\n",
    "explore_regex = e_re.Explore_Regex(sample_string) # Initaizlie the Explore regex Class.\n",
    "explore_regex.explore_pattern(pattern) # Use the .explore_pattern method.\n",
    "```\n",
    "\n",
    "\n",
    "Start with exploring the context around digits (\"\\d\") in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer 8.2.1-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# download data\n",
    "path2data = 'https://raw.githubusercontent.com/snorreralund/scraping_seminar/master/english_review_sample.csv'\n",
    "df = pd.read_csv(path2data)\n",
    "\n",
    "# download module\n",
    "url = 'https://raw.githubusercontent.com/snorreralund/explore_regex/master/explore_regex.py'\n",
    "response = requests.get(url)\n",
    "\n",
    "# write script to your folder to create a locate module\n",
    "with open('explore_regex.py','w') as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "# import local module\n",
    "import explore_regex as e_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "digit_re = re.compile('[0-9]+') \n",
    "df['hasNumber'] = df.reviewBody.apply(lambda x: len(digit_re.findall(x))>0)\n",
    "sample_string = '\\n'.join(df[df['hasNumber']].sample(1000).reviewBody)\n",
    "#sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_regex = e_re.ExploreRegex(sample_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Pattern: [£$] ?[0-9]+(?:[.,][0-9]+)?|[0-9]+(?:[.,][0-9]+)? ?(?:USD|usd)|[0-9]+(?:[.,][0-9]+)? ?(?:dollars|DOLLARS)\t Matched 234 patterns -----\n",
      "Match: 100 dollars\tContext:ed them that I lost 100 dollars because the dealer \n",
      "Match: $143\tContext:cover from them for $143.  So the 48-hour so\n",
      "Match: $8\tContext:.54), he charged me $8, which is the price\n",
      "Match: $5\tContext:ally was to give me $5 off my next order, \n",
      "Match: $7.99\tContext:\n",
      "I have been paying $7.99 a month for the las\n",
      "Match: $200\tContext:$800.  Asked for my $200 cash back that I us\n",
      "Match: $625\tContext: estimated quote of $625 and then where char\n",
      "Match: £40\tContext:he hotel cheaper by £40. Very happy and wil\n",
      "Match: $25.00\tContext:r $75.00 vice 3 for $25.00.\n",
      "Purchased 4 ticket\n",
      "Match: $10\tContext:l carbon plus about $10 worth of plastic pa\n"
     ]
    }
   ],
   "source": [
    "pattern = '[£$] ?[0-9]+(?:[.,][0-9]+)?|[0-9]+(?:[.,][0-9]+)? ?(?:USD|usd)|[0-9]+(?:[.,][0-9]+)? ?(?:dollars|DOLLARS)' #[£$] ?[0-9]+(?:[.,][0-9]+)?|[0-9]+(?:[.,][0-9]+)? ?(?:USD|usd)|\n",
    "\n",
    "explore_regex.explore_pattern(pattern,context=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex.8.2.3** Use the .report() method. e_re.report(), and print the all patterns in the development process using the .pattern method - i.e. e_re.patterns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#[Answer 8.2.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[£$] ?[0-9]+(?:[.,][0-9]+)?|[0-9]+(?:[.,][0-9]+)? ?(?:USD|usd)|[0-9]+(?:[.,][0-9]+)? ?(?:dollars|DOLLARS)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_regex.patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.4** \n",
    "Finally write a function that takes in a string and outputs if there is a match. Use the .match function to see if there is a match (hint if does not return a NoneType object - `re.match(pattern,string)!=None`).\n",
    "\n",
    "> Define a column 'mention_currency' in the dataframe, by applying the above function to the text column of the dataframe. \n",
    "*** You should have approximately 310 reviews that matches. - but less is also alright***\n",
    "\n",
    "> **Ex. 8.2.5** Explore the relation between reviews mentioning prices and the average rating. \n",
    "\n",
    "> **Ex. 8.2.6 (extra)** Define a function that outputs the amount mentioned in the review (if more than one the largest), define a new column by applying it to the data, and explore whether reviews mentioning higher prices are worse than others by plotting the amount versus the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer to 8.2.4-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '[£$] ?[0-9]+(?:[.,][0-9]+)?|[0-9]+(?:[.,][0-9]+)? ?(?:USD|usd)|[0-9]+(?:[.,][0-9]+)? ?(?:dollars|DOLLARS)'\n",
    "currency_re = re.compile(pattern)\n",
    "def match_currency(string):\n",
    "    return len(currency_re.findall(string))>0\n",
    "df['mention_currency'] = df.reviewBody.apply(match_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mention_currency\n",
       "False    4.507275\n",
       "True     2.935275\n",
       "Name: reviewRating_ratingValue, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('mention_currency').reviewRating_ratingValue.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.7:** Now we write a regular expression to extract emoticons from text.\n",
    "Start by locating all mouths ')' of emoticons, and develop the variations from there. Remember that paranthesis are special characters in regex, so you should use the escape character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer to 8.2.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_string = '\\n'.join(df.sample(1000).reviewBody)\n",
    "emoticon_regex = e_re.ExploreRegex(sample_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Pattern: [:;][-Oo]?[()D]\t Matched 11 patterns -----\n",
      "Match: :)\tContext:d Jedco to anyone.  :)\n",
      "It was a hassle fre\n",
      "Match: :)\tContext:ith Flyopedia again :)\n",
      "Great Product.  Del\n",
      "Match: :)\tContext:e bag of dog treats :)\n",
      "JustFly - super eas\n",
      "Match: :)\tContext:e with good bundles :)\n",
      "fast delivery, well\n",
      "Match: :)\tContext: phone call anxiety :)\n",
      "This process was de\n",
      "Match: :)\tContext:lpful. God bless her:)\n",
      "I was pleased with \n",
      "Match: :)\tContext:thank you HRKGames  :)\n",
      "I like Moos's produ\n",
      "Match: :)\tContext: that you are doing :)\n",
      "I love the site, th\n",
      "Match: :)\tContext:n the imei giveaway :)\n",
      "GoMedigap's represe\n",
      "Match: :)\tContext:lier than predicted :)\r\n",
      "\r\n",
      "Too bad you don'\n"
     ]
    }
   ],
   "source": [
    "pattern = '[:;][-Oo]?[()D]'\n",
    "emoticon_regex.explore_pattern(pattern,context=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[:;][-Oo]?[()D]': 11}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoticon_regex.pattern2n_match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
